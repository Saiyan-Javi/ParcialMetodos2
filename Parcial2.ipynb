{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c949c9fb",
   "metadata": {},
   "source": [
    "## Parcial 1 Métodos numéricos 2\n",
    "### Sección 10\n",
    "Javier Alejandro Ovalle Chiquín, 22103  \n",
    "Ricardo Josué Morales Contreras, 22289 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a827154",
   "metadata": {},
   "source": [
    "#### Probelma 1, responder si la afirmación es falsa 0 verdadera\n",
    "\n",
    "1. M admite factorización LU  \n",
    "2. M admite factorización PA = LU  \n",
    "3. M admite factorización SVD\n",
    "4. M admite factorización LL^t  \n",
    "5. M admite factorización QR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4c5e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M =\n",
      " [[1. 1. 0.]\n",
      " [0. 1. 1.]\n",
      " [0. 0. 1.]]\n",
      "\n",
      "(a) ¿M admite LU (sin pivoteo)? True\n",
      "Justificación: Triangular superior con diagonal no nula → pivotes 1,1,1 → LU sin pivoteo existe.\n",
      "\n",
      "(b) ¿M admite PA = LU (pivoteo parcial)? True\n",
      "Justificación: LU con pivoteo parcial siempre existe para matrices no singulares; verificación numérica OK.\n",
      "\n",
      "(c) ¿M admite SVD? True\n",
      "Justificación: SVD existe para cualquier matriz real; reconstrucción compacta correcta. singulares = [1.801938 1.24698  0.445042]\n",
      "\n",
      "(d) ¿M admite L L^T (Cholesky)? False\n",
      "Justificación: No: no es simétrica definida positiva (M ≠ M^T).\n",
      "\n",
      "(e) ¿M admite QR? True\n",
      "Justificación: descomposición QR siempre existe (Householder/Gram-Schmidt); verificación numérica OK.\n"
     ]
    }
   ],
   "source": [
    "# Ejercicio 1: factorizaciones para M\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "\n",
    "# Matriz del enunciado\n",
    "M = np.array([[1., 1., 0.],\n",
    "              [0., 1., 1.],\n",
    "              [0., 0., 1.]])\n",
    "\n",
    "print(\"M =\\n\", M)\n",
    "\n",
    "# ---------- Utilidades ----------\n",
    "def leading_principal_minors_nonzero(A):\n",
    "    \"\"\"Chequea si todos los menores principales líderes son no nulos.\"\"\"\n",
    "    for k in range(1, A.shape[0]+1):\n",
    "        if np.linalg.det(A[:k, :k]) == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def lu_nopivot(A):\n",
    "    \"\"\"Doolittle (sin pivoteo). Retorna L, U si es posible, si no lanza ValueError.\"\"\"\n",
    "    A = A.copy().astype(float)\n",
    "    n = A.shape[0]\n",
    "    L = np.zeros_like(A)\n",
    "    U = np.zeros_like(A)\n",
    "    for i in range(n):\n",
    "        L[i, i] = 1.0\n",
    "    for k in range(n):\n",
    "        # Pivote cero -> no se puede sin pivoteo\n",
    "        if abs(A[k, k]) < 1e-15:\n",
    "            raise ValueError(\"Pivote cero: LU sin pivoteo no es posible\")\n",
    "        # U fila k\n",
    "        for j in range(k, n):\n",
    "            U[k, j] = A[k, j] - L[k, :k] @ U[:k, j]\n",
    "        # L columna k\n",
    "        for i in range(k+1, n):\n",
    "            L[i, k] = (A[i, k] - L[i, :k] @ U[:k, k]) / U[k, k]\n",
    "    return L, U\n",
    "\n",
    "def lu_with_partial_pivot(A):\n",
    "    \"\"\"LU con pivoteo parcial: PA = LU. Retorna P, L, U.\"\"\"\n",
    "    A = A.copy().astype(float)\n",
    "    n = A.shape[0]\n",
    "    P = np.eye(n)\n",
    "    L = np.zeros_like(A)\n",
    "    U = A.copy()\n",
    "    for i in range(n):\n",
    "        # Pivoteo parcial\n",
    "        pivot = np.argmax(np.abs(U[i:, i])) + i\n",
    "        if abs(U[pivot, i]) < 1e-15:\n",
    "            raise ValueError(\"Matriz singular: pivote cero con pivoteo parcial.\")\n",
    "        # Intercambiar filas en U y P, y en L (columnas previas)\n",
    "        if pivot != i:\n",
    "            U[[i, pivot], i:] = U[[pivot, i], i:]\n",
    "            P[[i, pivot], :] = P[[pivot, i], :]\n",
    "            if i > 0:\n",
    "                L[[i, pivot], :i] = L[[pivot, i], :i]\n",
    "        # Eliminación\n",
    "        for j in range(i+1, n):\n",
    "            L[j, i] = U[j, i] / U[i, i]\n",
    "            U[j, i:] -= L[j, i] * U[i, i:]\n",
    "    np.fill_diagonal(L, 1.0)\n",
    "    return P, L, U\n",
    "\n",
    "def is_spd(A):\n",
    "    \"\"\"Chequea si es simétrica definida positiva.\"\"\"\n",
    "    if not np.allclose(A, A.T, atol=1e-12):\n",
    "        return False\n",
    "    # Autovalores todos positivos\n",
    "    w = np.linalg.eigvalsh(A)\n",
    "    return np.all(w > 1e-12)\n",
    "\n",
    "# ---------- (a) LU (sin pivoteo) ----------\n",
    "adm_lu = False\n",
    "lu_reason = \"\"\n",
    "try:\n",
    "    # Criterio práctico: pivotes diagonales no nulos en triangular => existe\n",
    "    L, U = lu_nopivot(M)\n",
    "    ok_recon = np.allclose(L @ U, M, atol=1e-12)\n",
    "    adm_lu = ok_recon\n",
    "    lu_reason = \"Triangular superior con diagonal no nula → pivotes 1,1,1 → LU sin pivoteo existe.\"\n",
    "except ValueError as e:\n",
    "    lu_reason = f\"No: {e}\"\n",
    "\n",
    "print(\"\\n(a) ¿M admite LU (sin pivoteo)?\", adm_lu)\n",
    "print(\"Justificación:\", lu_reason)\n",
    "\n",
    "# ---------- (b) PA = LU (con pivoteo parcial) ----------\n",
    "adm_pa_lu = False\n",
    "pa_lu_reason = \"\"\n",
    "try:\n",
    "    P, Lp, Up = lu_with_partial_pivot(M)\n",
    "    ok_pa = np.allclose(P @ M, Lp @ Up, atol=1e-10)\n",
    "    adm_pa_lu = ok_pa\n",
    "    pa_lu_reason = \"LU con pivoteo parcial siempre existe para matrices no singulares; verificación numérica OK.\"\n",
    "except ValueError as e:\n",
    "    pa_lu_reason = f\"No: {e}\"\n",
    "\n",
    "print(\"\\n(b) ¿M admite PA = LU (pivoteo parcial)?\", adm_pa_lu)\n",
    "print(\"Justificación:\", pa_lu_reason)\n",
    "\n",
    "# ---------- (c) SVD ----------\n",
    "# Siempre existe para cualquier matriz real.\n",
    "U, s, Vt = np.linalg.svd(M, full_matrices=False)\n",
    "svd_ok = np.allclose(U @ np.diag(s) @ Vt, M, atol=1e-10)\n",
    "print(\"\\n(c) ¿M admite SVD?\", svd_ok)\n",
    "print(\"Justificación: SVD existe para cualquier matriz real; reconstrucción compacta correcta. \"\n",
    "      f\"singulares = {s}\")\n",
    "\n",
    "# ---------- (d) LL^T (Cholesky) ----------\n",
    "adm_chol = False\n",
    "chol_reason = \"\"\n",
    "if is_spd(M):\n",
    "    adm_chol = True\n",
    "    chol_reason = \"M es simétrica definida positiva.\"\n",
    "else:\n",
    "    chol_reason = \"No: no es simétrica definida positiva (M ≠ M^T).\"\n",
    "print(\"\\n(d) ¿M admite L L^T (Cholesky)?\", adm_chol)\n",
    "print(\"Justificación:\", chol_reason)\n",
    "\n",
    "# ---------- (e) QR ----------\n",
    "# Siempre existe (Gram-Schmidt / Householder)\n",
    "Q, R = np.linalg.qr(M)\n",
    "qr_ok = np.allclose(Q @ R, M, atol=1e-10)\n",
    "print(\"\\n(e) ¿M admite QR?\", qr_ok)\n",
    "print(\"Justificación: descomposición QR siempre existe (Householder/Gram-Schmidt); verificación numérica OK.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8584e528",
   "metadata": {},
   "source": [
    "## Ejercicio 2 – SVD reducida y Vᵀ\n",
    "\n",
    "En clase vimos que la descomposición en valores singulares (SVD) reducida de una matriz \n",
    "\\(A \\in \\mathbb{R}^{m \\times n}\\) es de la forma:\n",
    "\n",
    "\n",
    "A = U \\Sigma Vᵀ\n",
    "\n",
    "\n",
    "donde:\n",
    "- \\(U \\in \\mathbb{R}^{m \\times k}\\) con \\(k = \\min(m,n)\\),\n",
    "- \\(\\Sigma \\in \\mathbb{R}^{k \\times k}\\) es diagonal con los valores singulares \\(\\sigma_i\\),\n",
    "- \\(V^\\top \\in \\mathbb{R}^{k \\times n}\\).\n",
    "\n",
    "En este ejercicio trabajamos con la matriz:\n",
    "\n",
    "\\[\n",
    "A =\n",
    "\\begin{bmatrix}\n",
    "1 & 5 & 3 & 2 & 4 \\\\\n",
    "2 & 2 & 0 & 4 & 1 \\\\\n",
    "2 & 1 & 8 & 4 & 2\n",
    "\\end{bmatrix}.\n",
    "\\]\n",
    "\n",
    "Al aplicar la función de Python:\n",
    "\n",
    "```python\n",
    "np.linalg.svd(A, full_matrices=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af004d4d",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### (a) ¿Por qué no se obtienen matrices $S$ y $V^\\top$ de tamaño $5 \\times 5$?\n",
    "\n",
    "La matriz $A$ es de tamaño $3 \\times 5$.  \n",
    "Cuando usamos `full_matrices=False`, NumPy devuelve la **SVD reducida**, donde:\n",
    "\n",
    "- $U \\in \\mathbb{R}^{3 \\times 3}$,\n",
    "- $\\Sigma \\in \\mathbb{R}^{3 \\times 3}$,\n",
    "- $V^\\top \\in \\mathbb{R}^{3 \\times 5}$.\n",
    "\n",
    "Esto ocurre porque la SVD reducida utiliza:\n",
    "\n",
    "$$\n",
    "k = \\min(m,n) = \\min(3,5) = 3,\n",
    "$$\n",
    "\n",
    "y solo genera las columnas/filas necesarias para reconstruir $A$.\n",
    "\n",
    "Conclusión: no aparecen matrices $5 \\times 5$ porque la versión reducida **omite la parte sobrante** de $V^\\top$ (y las dimensiones extra de $\\Sigma$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b83c1c",
   "metadata": {},
   "source": [
    "### (b.1) Cálculo de $V^\\top$ a mano (con todos los pasos)\n",
    "\n",
    "Queremos obtener $V^\\top$ de la descomposición SVD reducida de\n",
    "\n",
    "$$\n",
    "A=\n",
    "\\begin{bmatrix}\n",
    "1 & 5 & 3 & 2 & 4 \\\\\n",
    "2 & 2 & 0 & 4 & 1 \\\\\n",
    "2 & 1 & 8 & 4 & 2\n",
    "\\end{bmatrix}\\in\\mathbb{R}^{3\\times 5}.\n",
    "$$\n",
    "\n",
    "Recordemos que:\n",
    "\n",
    "$$\n",
    "A^\\top A = V\\,\\Sigma^2\\,V^\\top.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Paso 1. Construir $A^\\top A$**\n",
    "\n",
    "Multiplicamos:\n",
    "\n",
    "$$\n",
    "A^\\top A =\n",
    "\\begin{bmatrix}\n",
    "9 & 9 & 19 & 14 & 12 \\\\\n",
    "9 & 30 & 31 & 24 & 28 \\\\\n",
    "19 & 31 & 73 & 42 & 42 \\\\\n",
    "14 & 24 & 42 & 36 & 20 \\\\\n",
    "12 & 28 & 42 & 20 & 21\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Paso 2. Calcular los autovalores de $A^\\top A$**\n",
    "\n",
    "Resolviendo $\\det(A^\\top A - \\lambda I)=0$, se obtienen los autovalores (ordenados descendentemente):\n",
    "\n",
    "$$\n",
    "\\lambda_1 \\approx 132.41523, \\quad\n",
    "\\lambda_2 = 25, \\quad\n",
    "\\lambda_3 \\approx 11.58477, \\quad\n",
    "\\lambda_4 = 0, \\quad\n",
    "\\lambda_5 = 0.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Paso 3. Relación entre autovalores y valores singulares**\n",
    "\n",
    "Recordemos:  \n",
    "$$\n",
    "\\sigma_i = \\sqrt{\\lambda_i}.\n",
    "$$\n",
    "\n",
    "Por lo tanto:\n",
    "\n",
    "$$\n",
    "\\sigma_1 \\approx 11.507182, \\quad\n",
    "\\sigma_2 = 5, \\quad\n",
    "\\sigma_3 \\approx 3.403641.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Paso 4. Calcular los autovectores de $A^\\top A$**\n",
    "\n",
    "Para cada $\\lambda_i > 0$, resolvemos\n",
    "\n",
    "$$\n",
    "(A^\\top A - \\lambda_i I)v_i = 0,\n",
    "$$\n",
    "\n",
    "y normalizamos $v_i$ para que tenga norma 1.  \n",
    "Esto nos da los tres **vectores singulares derechos** principales:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v_1^\\top &\\approx [-0.234763,\\ -0.362728,\\ -0.683161,\\ -0.469526,\\ -0.355177], \\\\\n",
    "v_2^\\top &\\approx [\\ 0.052686,\\ \\ 0.684922,\\ -0.632236,\\ \\ 0.105373,\\ \\ 0.342461], \\\\\n",
    "v_3^\\top &\\approx [-0.375416,\\ \\ 0.270858,\\ \\ 0.322852,\\ -0.750832,\\ \\ 0.343099].\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Paso 5. Completar la base con autovectores del núcleo**\n",
    "\n",
    "Como $A$ tiene rango 3, hay dos autovalores iguales a 0.  \n",
    "Sus autovectores corresponden al **núcleo de $A$**, y completan la base ortonormal:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v_4^\\top &\\approx [-0.870767,\\ \\ 0.153327,\\ \\ 0.045998,\\ \\ 0.412385,\\ -0.214658], \\\\\n",
    "v_5^\\top &\\approx [-0.207213,\\ -0.549942,\\ -0.164983,\\ \\ 0.186098,\\ \\ 0.769919].\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Paso 6. Formar $V$ y transponer**\n",
    "\n",
    "La matriz $V$ se construye con estas columnas:\n",
    "\n",
    "$$\n",
    "V = [v_1\\ v_2\\ v_3\\ v_4\\ v_5],\n",
    "$$\n",
    "\n",
    "y por lo tanto\n",
    "\n",
    "$$\n",
    "V^\\top \\approx\n",
    "\\begin{bmatrix}\n",
    "-0.234763 & -0.362728 & -0.683161 & -0.469526 & -0.355177 \\\\\n",
    "\\ \\ 0.052686 & \\ \\ 0.684922 & -0.632236 & \\ \\ 0.105373 & \\ \\ 0.342461 \\\\\n",
    "-0.375416 & \\ \\ 0.270858 & \\ \\ 0.322852 & -0.750832 & \\ \\ 0.343099 \\\\\n",
    "-0.870767 & \\ \\ 0.153327 & \\ \\ 0.045998 & \\ \\ 0.412385 & -0.214658 \\\\\n",
    "-0.207213 & -0.549942 & -0.164983 & \\ \\ 0.186098 & \\ \\ 0.769919\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Paso 7. Verificación**\n",
    "\n",
    "1. Los vectores de $V$ son ortonormales ($V^\\top V=I$).  \n",
    "2. Con $\\Sigma=\\operatorname{diag}(\\sigma_1,\\sigma_2,\\sigma_3,0,0)$ se cumple:\n",
    "\n",
    "$$\n",
    "A^\\top A = V \\Sigma^2 V^\\top,\n",
    "$$\n",
    "\n",
    "y por la definición de SVD:\n",
    "\n",
    "$$\n",
    "A = U \\Sigma V^\\top.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "648780d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores singulares (σ): [11.507181664855  5.              3.403640717236]\n",
      "V^T completo (5x5):\n",
      " [[-0.234762846438 -0.362728440875 -0.683161270311 -0.469525692875\n",
      "  -0.355177120026]\n",
      " [ 0.052686336977  0.684922380706 -0.632236043729  0.105372673955\n",
      "   0.342461190353]\n",
      " [-0.375415973235  0.270858209012  0.322851656414 -0.75083194647\n",
      "   0.343098927076]\n",
      " [-0.870767491377  0.153326844118  0.045998053235  0.412384719071\n",
      "  -0.214657581765]\n",
      " [-0.20721336547  -0.549941924272 -0.164982577282  0.186097971376\n",
      "   0.769918693981]]\n",
      "\n",
      "Autovalores de A^T A (desc): [132.415229867973  25.              11.584770132027   0.\n",
      "  -0.            ]\n",
      "V^T (5x5) vía eigen:\n",
      " [[-0.234762846438 -0.362728440875 -0.683161270311 -0.469525692875\n",
      "  -0.355177120026]\n",
      " [ 0.052686336977  0.684922380706 -0.632236043729  0.105372673955\n",
      "   0.342461190353]\n",
      " [-0.375415973235  0.270858209012  0.322851656414 -0.75083194647\n",
      "   0.343098927076]\n",
      " [-0.124556058096  0.567987663359  0.170396299008 -0.022920120456\n",
      "  -0.795182728702]\n",
      " [-0.88637418242  -0.057751670726 -0.017325501218  0.451849841819\n",
      "   0.080852339017]]\n",
      "\n",
      "V^T reducido (3x5) vía relación (A^T U)/σ:\n",
      " [[-0.234762846438 -0.362728440875 -0.683161270311 -0.469525692875\n",
      "  -0.355177120026]\n",
      " [ 0.052686336977  0.684922380706 -0.632236043729  0.105372673955\n",
      "   0.342461190353]\n",
      " [-0.375415973235  0.270858209012  0.322851656414 -0.75083194647\n",
      "   0.343098927076]]\n"
     ]
    }
   ],
   "source": [
    "# Matriz A (3x5)\n",
    "A = np.array([\n",
    "    [1., 5., 3., 2., 4.],\n",
    "    [2., 2., 0., 4., 1.],\n",
    "    [2., 1., 8., 4., 2.]\n",
    "])\n",
    "\n",
    "# ---- Opción 1: SVD completa\n",
    "U_full, s_full, Vt_full = np.linalg.svd(A, full_matrices=True)\n",
    "print(\"Valores singulares (σ):\", s_full)\n",
    "print(\"V^T completo (5x5):\\n\", Vt_full)\n",
    "\n",
    "# ---- Opción 2: Eigen de A^T A\n",
    "ATA = A.T @ A\n",
    "eigvals, eigvecs = np.linalg.eigh(ATA)\n",
    "idx = np.argsort(eigvals)[::-1]\n",
    "eigvals = eigvals[idx]\n",
    "eigvecs = eigvecs[:, idx]\n",
    "Vt_from_eigh = eigvecs.T\n",
    "print(\"\\nAutovalores de A^T A (desc):\", eigvals)\n",
    "print(\"V^T (5x5) vía eigen:\\n\", Vt_from_eigh)\n",
    "\n",
    "# ---- Opción 3: Relación v_i = (A^T u_i)/σ_i\n",
    "U_red, s_red, Vt_red = np.linalg.svd(A, full_matrices=False)\n",
    "V_from_relation = (A.T @ U_red) / s_red\n",
    "Vt_from_relation = V_from_relation.T\n",
    "print(\"\\nV^T reducido (3x5) vía relación (A^T U)/σ:\\n\", Vt_from_relation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630b1927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f702e6f",
   "metadata": {},
   "source": [
    "## Problema 3\n",
    "\n",
    "Hallar la matriz inversa de\n",
    "\n",
    "$\n",
    "T =\n",
    "\\begin{pmatrix}\n",
    "-1 & -1 & 0 & 0 & 0 & 0 \\\\\n",
    "1 & 0 & 0 & -1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & 0 & -1 \\\\\n",
    "0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & -1 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & -1 & 1\n",
    "\\end{pmatrix}\n",
    "$\n",
    "\n",
    "de forma eficiente.\n",
    "¿Cuál es la complejidad computacional del algoritmo utilizado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74ab0cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz T =\n",
      " [[-1. -1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0. -1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0. -1.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0. -1.  1.]]\n",
      "\n",
      "Matriz inversa T^{-1} =\n",
      " [[-1. -0. -1. -1. -1. -1.]\n",
      " [-0. -0.  1.  1.  1.  1.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1.]\n",
      " [ 0.  0.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  1.  1.  1.]]\n",
      "\n",
      "Verificación ||T T^{-1} - I||_F = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Problema 3 - Inversa de T por LU con pivoteo parcial\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "\n",
    "# Definir la matriz T (6x6)\n",
    "T = np.array([\n",
    "    [-1., -1.,  0.,  0.,  0.,  0.],\n",
    "    [ 1.,  0.,  0., -1.,  0.,  0.],\n",
    "    [ 0.,  1.,  0.,  0.,  0., -1.],\n",
    "    [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
    "    [ 0.,  0., -1.,  0.,  1.,  0.],\n",
    "    [ 0.,  0.,  0.,  0., -1.,  1.],\n",
    "])\n",
    "\n",
    "# --- LU con pivoteo parcial ---\n",
    "def lu_with_partial_pivot(A):\n",
    "    A = A.copy().astype(float)\n",
    "    n = A.shape[0]\n",
    "    P = np.eye(n)\n",
    "    L = np.zeros_like(A)\n",
    "    U = A.copy()\n",
    "    for i in range(n):\n",
    "        # Buscar pivote\n",
    "        pivot = np.argmax(np.abs(U[i:, i])) + i\n",
    "        if np.isclose(U[pivot, i], 0.0):\n",
    "            raise ValueError(\"Matriz singular.\")\n",
    "        # Intercambiar filas\n",
    "        if pivot != i:\n",
    "            U[[i, pivot], i:] = U[[pivot, i], i:]\n",
    "            P[[i, pivot], :] = P[[pivot, i], :]\n",
    "            if i > 0:\n",
    "                L[[i, pivot], :i] = L[[pivot, i], :i]\n",
    "        # Eliminación\n",
    "        for j in range(i+1, n):\n",
    "            L[j, i] = U[j, i] / U[i, i]\n",
    "            U[j, i:] -= L[j, i] * U[i, i:]\n",
    "    np.fill_diagonal(L, 1.0)\n",
    "    return P, L, U\n",
    "\n",
    "def forward_substitution(L, b):\n",
    "    y = b.astype(float).copy()\n",
    "    for i in range(L.shape[0]):\n",
    "        y[i] -= L[i, :i] @ y[:i]\n",
    "    return y  # diag(L)=1\n",
    "\n",
    "def back_substitution(U, y):\n",
    "    x = y.astype(float).copy()\n",
    "    n = U.shape[0]\n",
    "    for i in range(n-1, -1, -1):\n",
    "        x[i] -= U[i, i+1:] @ x[i+1:]\n",
    "        x[i] /= U[i, i]\n",
    "    return x\n",
    "\n",
    "# Factorizar una vez\n",
    "P, L, U = lu_with_partial_pivot(T)\n",
    "\n",
    "# Resolver T X = I (para obtener T^{-1})\n",
    "I = np.eye(T.shape[0])\n",
    "cols = []\n",
    "for k in range(T.shape[0]):\n",
    "    pb = P @ I[:, k]\n",
    "    y  = forward_substitution(L, pb)\n",
    "    x  = back_substitution(U, y)\n",
    "    cols.append(x)\n",
    "\n",
    "T_inv = np.column_stack(cols)\n",
    "\n",
    "print(\"Matriz T =\\n\", T)\n",
    "print(\"\\nMatriz inversa T^{-1} =\\n\", T_inv)\n",
    "print(\"\\nVerificación ||T T^{-1} - I||_F =\", np.linalg.norm(T @ T_inv - I, ord='fro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca9bd1c",
   "metadata": {},
   "source": [
    "### Problema 3 — Inversa de $T$\n",
    "\n",
    "Lo que hicimos aquí fue sacar la inversa de la matriz $T$ usando una **factorización LU con pivoteo parcial**.  \n",
    "La idea no es calcular la inversa “a lo bruto” (que sería más costoso), sino factorizar $T$ una sola vez como $LU$ y luego resolver $T X = I$ para ir sacando cada columna de la inversa.  \n",
    "\n",
    "Al final nos dio una $T^{-1}$ que cumple perfecto:\n",
    "\n",
    "$$\n",
    "\\| T T^{-1} - I \\|_F = 0,\n",
    "$$\n",
    "\n",
    "así que sabemos que está bien hecha.\n",
    "\n",
    "---\n",
    "\n",
    "### Complejidad\n",
    "\n",
    "- La parte pesada es la **LU**, que cuesta $O(n^3)$.  \n",
    "- Después, resolver $n$ sistemas triangulares (uno por cada columna de la identidad) cuesta en total también $O(n^3)$.  \n",
    "- En resumen: todo el proceso sigue siendo $O(n^3)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0b2123",
   "metadata": {},
   "source": [
    "#%% md\n",
    "# Problema 4\n",
    "\n",
    "Suponga que se tiene un conjunto de 12 pares de datos $\\{(x_i, y_i)\\}_{i=1}^{12}$, donde $x_i \\in \\mathbb{R}^3$ y $y_i \\in \\mathbb{R}$.\n",
    "\n",
    "Se desea construir un modelo de regresión lineal de la forma\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\epsilon,$$\n",
    "\n",
    "donde $\\beta = (\\beta_0, \\beta_1, \\beta_2, \\beta_3)^T$ es el vector de coeficientes del modelo, y $x = (x_1, x_2, x_3)^T \\in \\mathbb{R}^3$ son las observaciones, y el término $\\epsilon \\sim \\mathcal{N}(0, \\sigma)$ es la variable aleatoria del ruido asociado a la incerteza.\n",
    "\n",
    "Para ello, se construye la matriz de diseño del modelo\n",
    "\n",
    "$$\n",
    "\\mathbf{X} =\n",
    "\\begin{pmatrix}\n",
    "1 & 0.001 & 1 & 3 \\\\\n",
    "1 & 0.002 & 1.001 & 3 \\\\\n",
    "1 & 0.003 & 1.002 & 3 \\\\\n",
    "1 & 0.004 & 1 & 3.001 \\\\\n",
    "1 & 0.005 & 1.001 & 3.001 \\\\\n",
    "1 & 0.006 & 1.002 & 3.001 \\\\\n",
    "1 & 0.006 & 1 & 3.002 \\\\\n",
    "1 & 0.005 & 1.001 & 3.002 \\\\\n",
    "1 & 0.004 & 1.002 & 3.002 \\\\\n",
    "1 & 0.003 & 1 & 3.003 \\\\\n",
    "1 & 0.002 & 1.001 & 3.003 \\\\\n",
    "1 & 0.001 & 1.002 & 3.003\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "\n",
    "y el vector de observaciones $y = (y_1, y_2, \\ldots, y_{12})^T$.\n",
    "\n",
    "Se sabe que los coeficientes óptimos (el estimador de máxima verosimilitud del modelo de regresión), $\\hat{\\beta}$, están dados por\n",
    "\n",
    "$$(\\mathbf{X}^T \\mathbf{X})^{-1} \\hat{\\beta} = \\mathbf{X}^T \\mathbf{y},$$\n",
    "\n",
    "y la varianza del coeficiente $\\hat{\\beta}_j$ es proporcional a\n",
    "\n",
    "$$\\text{Var}(\\hat{\\beta}j) = \\sigma^2 C{jj},$$\n",
    "\n",
    "donde $C_{jj}$ es la j–ésima entrada en la diagonal de la matriz $C = (\\mathbf{X}^T \\mathbf{X})^{-1}$. Con base en lo anterior\n",
    "\n",
    "a) Hallar el número de condición del sistema.\n",
    "\n",
    "b) ¿El sistema es estable? ¿Por qué?\n",
    "\n",
    "c) ¿Cuáles son las causas de lo anterior?\n",
    "\n",
    "d) Asumiendo $\\sigma = 1$, ¿Cuáles son las varianzas de cada coeficiente?\n",
    "    ¿Qué puede inferir sobre los valores de los coeficientes y sobre la calidad de su modelo de regresión?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "368477d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores singulares de X: [11.494877076365  0.005916077777  0.002958781936  0.001115742827]\n",
      "Número de condición kappa(X): 10302.443181954317\n",
      "Autovalores de X^T X: [  0.000001244882   0.000008754391   0.000034999976 132.132199000751]\n",
      "Número de condición kappa(X^T X): 106140334.84471254\n",
      "\n",
      "Varianzas de los coeficientes (sigma^2=1): [725850.7084675523    28571.428571428543 125000.00001028333\n",
      "  66666.66665621131 ]\n"
     ]
    }
   ],
   "source": [
    "# Problema 4 - Análisis de condición y varianzas en regresión lineal\n",
    "np.set_printoptions(precision=12, suppress=True)\n",
    "\n",
    "# Matriz de diseño X (12x4)\n",
    "X = np.array([\n",
    "    [1, 0.001, 1.000, 3.000],\n",
    "    [1, 0.002, 1.001, 3.000],\n",
    "    [1, 0.003, 1.002, 3.000],\n",
    "    [1, 0.004, 1.000, 3.001],\n",
    "    [1, 0.005, 1.001, 3.001],\n",
    "    [1, 0.006, 1.002, 3.001],\n",
    "    [1, 0.006, 1.000, 3.002],\n",
    "    [1, 0.005, 1.001, 3.002],\n",
    "    [1, 0.004, 1.002, 3.002],\n",
    "    [1, 0.003, 1.000, 3.003],\n",
    "    [1, 0.002, 1.001, 3.003],\n",
    "    [1, 0.001, 1.002, 3.003],\n",
    "], dtype=float)\n",
    "\n",
    "# (a) Número de condición de X y de X^T X\n",
    "U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "kappa_X = s.max() / s.min()\n",
    "XtX = X.T @ X\n",
    "eigvals = np.linalg.eigvalsh(XtX)\n",
    "kappa_XtX = eigvals.max() / eigvals.min()\n",
    "\n",
    "print(\"Valores singulares de X:\", s)\n",
    "print(\"Número de condición kappa(X):\", kappa_X)\n",
    "print(\"Autovalores de X^T X:\", eigvals)\n",
    "print(\"Número de condición kappa(X^T X):\", kappa_XtX)\n",
    "\n",
    "# (d) Varianzas de los coeficientes (sigma^2=1)\n",
    "C = np.linalg.inv(XtX)\n",
    "variances = np.diag(C)\n",
    "print(\"\\nVarianzas de los coeficientes (sigma^2=1):\", variances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a55ac7",
   "metadata": {},
   "source": [
    "### Interpretación de los resultados\n",
    "\n",
    "- **Valores singulares de X:**  \n",
    "  Salieron `[11.49, 0.0059, 0.0029, 0.0011]`.  \n",
    "  Esto muestra una diferencia enorme entre el mayor y el menor ⇒ algunas direcciones de los datos aportan mucha información y otras son casi redundantes.  \n",
    "\n",
    "- **Número de condición de X:**  \n",
    "  $\\kappa(X) \\approx 1.03 \\times 10^4$.  \n",
    "  Es altísimo: cualquier error pequeño en los datos puede amplificarse miles de veces en los coeficientes.  \n",
    "\n",
    "- **Autovalores de $X^\\top X$:**  \n",
    "  `[1.25e-6, 8.75e-6, 3.5e-4, 132.13]`.  \n",
    "  Varios son casi cero ⇒ $X^\\top X$ es casi singular, lo que confirma problemas de multicolinealidad.  \n",
    "\n",
    "- **Número de condición de $X^\\top X$:**  \n",
    "  $\\kappa(X^\\top X) \\approx 1.06 \\times 10^8$.  \n",
    "  Recordemos que la condición se **cuadra** cuando trabajamos con ecuaciones normales, por eso es mucho peor que la de $X$.  \n",
    "\n",
    "- **Varianzas de los coeficientes (σ² = 1):**  \n",
    "  $[725{,}850.7,\\; 28{,}571.4,\\; 125{,}000,\\; 66{,}666.7]$.  \n",
    "  Son enormes ⇒ hay muchísima incertidumbre en los coeficientes estimados, los intervalos de confianza serían muy anchos y el modelo es poco confiable.\n",
    "\n",
    "---\n",
    "\n",
    "**Conclusión:** la matriz de diseño está mal condicionada, lo que vuelve inestable la regresión.  \n",
    "En la práctica se recomendaría **escalar/centrar variables**, usar **QR/SVD** en lugar de ecuaciones normales o aplicar **regularización (ridge)** para mejorar la estabilidad.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
